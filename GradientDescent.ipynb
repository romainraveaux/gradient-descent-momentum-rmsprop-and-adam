{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Descent : Momentum, RMSProp and ADAM\n",
    "\n",
    "## Author : Romain Raveaux\n",
    "Gradient descent is an algorithm to find the parameters of a model.\n",
    "\n",
    "On the basis of a set of data set comprising M input values $X = (x_1, . . . , x_M)^T$ and their corresponding target values $T = (t_1, . . . , t_M)^T$, we want to find the parameters $W$ of the model $f(x,W)$ such that a given criterion is minimized. \n",
    "\n",
    "## The criterion\n",
    "\n",
    "In machine learning, the criterion is often an error function such that : \n",
    "$$L(X,T,W)=\\frac{1}{M}\\sum_{n=1}^M { \\{ f(x_n,W)-t_n }\\}^2 $$\n",
    "$$or$$\n",
    "$$L(X,T,W)=\\frac{-1}{M}\\sum_{n=1}^M \\{   t_n \\log (f(x_n,W))  +  (1-t_n) \\log( 1-f(x_n,W) )  \\} \\quad \\text{with }t_n \\in \\{0,1\\}$$\n",
    "\n",
    "## The optimization problem\n",
    "\n",
    "The optimization problem is then defined as :\n",
    "$$ W^*=arg \\min_W L(X,T,W)$$\n",
    "\n",
    "We are seeking for the minimum of the function $L$ so we need to find where the derivative of the function is equal to zero:\n",
    "$$\\dfrac{\\partial L(X,T,W)}{\\partial W} = 0 $$ \n",
    "This can be done by the gradient descent method. \n",
    "\n",
    "\n",
    "## Gradient descent method\n",
    "If the fonction $L$ is convex then we can start with any random parameters $W$ and reach the global minimum of $L$ by gradient descent. If the the problem is not convex then the gradient descent method only finds a suboptimal solution.\n",
    "\n",
    "The goal is to choose the parameter update to comprise a small step in the direction of the negative gradient, so that\n",
    "$$W^{(t+1)}=W^{(t)}-\\alpha. \\dfrac{\\partial L}{\\partial W^{(t)}}$$\n",
    "where the parameter $\\alpha > 0$ is known as the learning rate.\n",
    "\n",
    "\n",
    "## Issue of the Gradient descent\n",
    "\n",
    "The gradient on its own can be a bit noisy it means it changes a lot at each iteration. In order to get a clear trend on the gradient values, it is possible to make it smoother.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Momemtum and Gradient descent\n",
    "\n",
    "## The principle\n",
    "The iterations of the algorithm are modified as follows:\n",
    "$$U_{dw}^{(t)}=\\beta U_{dw}^{(t-1)} +(1- \\beta ) \\dfrac{\\partial L}{\\partial W^{(t)}}$$\n",
    "The update of the parameters is as follows : \n",
    "$$W^{(t+1)}=W^{(t)}-\\alpha. U_{dw}^{(t)}$$\n",
    "\n",
    "## Hyper parameters\n",
    "The first value that is often set to 0:\n",
    "$$U_{dw}^{(t=0)}=0$$\n",
    "$\\beta$ is a hyper parameter that is often set to $0.9$.\n",
    "\n",
    "## What it is doing\n",
    "\n",
    "Momemtm is averaging past gradient values. The average is an exponential average. It means that each value of the gradient is weighted by an exponential function $\\beta^t$ (see figure).\n",
    "![Figure](./expweightedaveragev2.PNG)\n",
    "\n",
    "$$U_{dw}^{(100)}=0.9 U_{dw}^{(99)} +0.1 \\dfrac{\\partial L}{\\partial W^{(100)}}$$\n",
    "$$U_{dw}^{(99)}=0.9 U_{dw}^{(98)} +0.1 \\dfrac{\\partial L}{\\partial W^{(99)}}$$\n",
    "$$U_{dw}^{(98)}=0.9 U_{dw}^{(97)} +0.1 \\dfrac{\\partial L}{\\partial W^{(98)}}$$\n",
    "$$...$$\n",
    "Re-arranging, we can express $U_{dw}^{(100)}$ with the past values : \n",
    "$$U_{dw}^{(100)}=0.9 \\big\\{ 0.9 U_{dw}^{(98)} +0.1 \\dfrac{\\partial L}{\\partial W^{(99)}} \\big\\}+0.1 \\dfrac{\\partial L}{\\partial W^{(100)}}$$\n",
    "$$U_{dw}^{(100)}=\\big\\{ 0.9^2 U_{dw}^{(98)} +0.9 \\dfrac{\\partial L}{\\partial W^{(99)}} \\big\\}+0.1 \\dfrac{\\partial L}{\\partial W^{(100)}}$$\n",
    "\n",
    "$$U_{dw}^{(100)}= \\big\\{  \\big( 0.9^3 U_{dw}^{(97)} +0.9^2 \\dfrac{\\partial L}{\\partial W^{(98)}} \\big) +0.9 \\dfrac{\\partial L}{\\partial W^{(99)}} \\big\\}+0.1 \\dfrac{\\partial L}{\\partial W^{(100)}}$$\n",
    "** The exponential weighting is appearing.**\n",
    "\n",
    "By setting $\\beta=0.9$ then it is actually averaging the 10 gradient values from the 10 past iterations. The gradient at the iteration 10 is then divided by 3 making it less significant.\n",
    "More generally, Momemtum is actually averaging approximately $\\frac{1}{1-\\beta}$ iterations.\n",
    "$$(1- \\epsilon)^{\\frac{1}{\\epsilon}}=\\frac{1}{e}=0.35$$\n",
    "With $\\epsilon=(1-\\beta)$, we obtain:\n",
    "$$\\frac{1}{1-\\beta}$$\n",
    "\n",
    "\n",
    "By seetting these values, we see that the methods will need a warm up phase. The first value $U_{dw}^{(t=0)}=0$ will have a strong impact at the beginning. However, in practice, after 10 iterations the bias introduced by the first value will disappear.\n",
    "It is also paossible to correct this behaviour with a normalization that is called **bias correction** :\n",
    "$$U_{dw}^{(t,corrected)}=\\frac{U_{dw}^{(t)}}{1 -\\beta^t} $$\n",
    "\n",
    "Note that in statistics, this procedure is called an **exponentially weighted average**.\n",
    "\n",
    "## The advantage\n",
    "It only takes one line of code and one real number is kept in memory\n",
    "\n",
    "## TODO : Code the Momemtum principle, play with $\\beta$, implement the bias correction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RMS Prop and Gradient descent\n",
    "Root Mean Squared Prop\n",
    "\n",
    "## The principle\n",
    "The iterations of the algorithm are modified as follows:\n",
    "$$S_{dw}^{(t)}=\\beta_2 S_{dw}^{(t-1)} +(1- \\beta_2 ) \\big\\{ \\dfrac{\\partial L}{\\partial W^{(t)}} \\big\\}^2$$\n",
    "The update of the parameters is as follows : \n",
    "$$W^{(t+1)}=W^{(t)}-\\alpha. \\dfrac{\\partial L}{\\partial W^{(t)}} \\frac{1}{\\sqrt{S_{dw}^{(t)}}}$$\n",
    "\n",
    "To prevent $\\sqrt(0)$, it is possible to add $\\epsilon=10^{-8} :$ \n",
    "$$\\frac{1}{\\sqrt{S_{dw}^{(t)}+\\epsilon}}$$\n",
    "\n",
    "## What it is doing\n",
    "The square that is put on the gradient will emphase large gradient values such that $ \\big\\{ \\dfrac{\\partial L}{\\partial W^{(t)}} \\big\\}^2$ will get very large. Consequently, $S_{dw}^{(t)}$ will be very high too.\n",
    "Accordingly, in the update rule, a large gradient value $\\dfrac{\\partial L}{\\partial W^{(t)}}$ will be divided by a large value of $S_{dw}^{(t)}$. **It will reduce high variations of the gradient**.\n",
    "\n",
    "### RMS prop reduces the gradient oscillations and allows the use of a large learning rate\n",
    "\n",
    "### Legend : The legend says that this approach was not proposed in an academic research paper but during a course on Coursera made by Geoffrey Hinton.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ADAM optimizer\n",
    "ADAM = Adapt Moment Adaptation\n",
    "\n",
    "## The principle at iteration $t$\n",
    "The iterations of the algorithm are modified as follows:\n",
    "$$U_{dw}^{(t)}=\\beta_1 U_{dw}^{(t-1)} +(1- \\beta_1 ) \\dfrac{\\partial L}{\\partial W^{(t)}} \\to \\text{ This is momemtum}$$ \n",
    "$$S_{dw}^{(t)}=\\beta_2 S_{dw}^{(t-1)} +(1- \\beta_2 ) \\big\\{ \\dfrac{\\partial L}{\\partial W^{(t)}} \\big\\}^2 \\to \\text{ This is RMS prop}$$\n",
    "\n",
    "The update of the parameters is as follows : \n",
    "$$W^{(t+1)}=W^{(t)}-\\alpha. \\dfrac{\\partial L}{\\partial W^{(t)}} \\frac{U_{dw}^{(t)}}{\\sqrt{S_{dw}^{(t)}}}$$\n",
    "\n",
    "It is also possible to apply bias correction on $U_{dw}^{(t)}$ and $S_{dw}^{(t)}$.\n",
    "## The principle\n",
    "ADAM is combining Momemtum and RMS prop\n",
    "\n",
    "## Hyper parameters\n",
    "$$\\beta_1 = 0.9$$\n",
    "$$\\beta_2 = 0.999$$\n",
    "$$\\epsilon=10^{-8}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning rate decay\n",
    "\n",
    "If $\\alpha$ is high then the method will not converge and it will keep on oscillating. At the opposite, if $\\alpha$ is low then convergence will be slow. \n",
    "\n",
    "A compromise would be to have a large learning rate at the beginning and then after some iterations, we could reduce the learning rate to obtain smaller oscillations in a tighter region of the solution space.\n",
    "$$\\alpha=\\frac{1}{1+decay*t}\\alpha_0$$\n",
    "With :\n",
    "$$\\alpha_0=0.1$$\n",
    "$${decay}=1$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
